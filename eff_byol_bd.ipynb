{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from astra.torch.utils import train_fn\n",
    "from astra.torch.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19124, 3, 224, 224]) torch.Size([19124]) torch.Size([6375, 3, 224, 224]) torch.Size([6375])\n",
      "torch.Size([25499, 3, 224, 224]) torch.Size([25499])\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/vannsh.jani/brick_kilns/ssl_exp/data\"\n",
    "x_train = torch.load(join(path, \"ban_x_train.pt\"))\n",
    "y_train = torch.load(join(path, \"ban_y_train.pt\"))\n",
    "x_test = torch.load(join(path, \"ban_x_test.pt\"))\n",
    "y_test = torch.load(join(path, \"ban_y_test.pt\"))\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "x_b = torch.cat([x_train, x_test], dim=0).to(device)\n",
    "y_b = torch.cat([y_train, y_test], dim=0).to(device)\n",
    "\n",
    "print(x_b.shape, y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5013, 3, 224, 224]) torch.Size([5013])\n"
     ]
    }
   ],
   "source": [
    "x_d = torch.load(join(path, \"delhi_test_images_50.pt\")).to(device)\n",
    "y_d = torch.load(join(path, \"delhi_test_labels_50.pt\"))\n",
    "print(x_d.shape, y_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([501, 3, 224, 224]) torch.Size([501])\n"
     ]
    }
   ],
   "source": [
    "x_d_train = torch.load(join(path, \"delhi_5_images.pt\")).to(device)\n",
    "y_d_train = torch.load(join(path, \"delhi_5_labels.pt\")).long().to(device)\n",
    "print(x_d_train.shape, y_d_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26000, 3, 224, 224]) torch.Size([26000])\n"
     ]
    }
   ],
   "source": [
    "x_b = torch.cat([x_b, x_d_train], dim=0)\n",
    "y_b = torch.cat([y_b, y_d_train], dim=0)\n",
    "print(x_b.shape, y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downstream model\n",
    "class DownstreamModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        eff = torchvision.models.efficientnet_b0(weights=None)\n",
    "        self.eff = nn.Sequential(*list(eff.children())[:-1])\n",
    "        self.last_layer = list(eff.children())[-1]\n",
    "        self.eff.load_state_dict(torch.load(\"/home/vannsh.jani/brick_kilns/ssl_exp/byol/byol_bd_150.pth\"))\n",
    "        self.last_layer[1] = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.eff(x).squeeze(-2, -1)\n",
    "        # print(x.shape)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DownstreamModel(2).to(device)\n",
    "model(torch.rand(2, 3, 224, 224).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.11318561: 100%|██████████| 1/1 [00:24<00:00, 24.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9585)\n",
      "Precision: tensor(0.8637)\n",
      "Recall: tensor(0.7666)\n",
      "F1 Score: tensor(0.8123)\n",
      "Train Loss: 0.0365619617468547\n",
      "Test Loss: 0.10499097108840942\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03395295: 100%|██████████| 1/1 [00:24<00:00, 24.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9565)\n",
      "Precision: tensor(0.8848)\n",
      "Recall: tensor(0.7447)\n",
      "F1 Score: tensor(0.8088)\n",
      "Train Loss: 0.024573565299061517\n",
      "Test Loss: 0.11693883212283254\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01622165: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9587)\n",
      "Precision: tensor(0.8407)\n",
      "Recall: tensor(0.7794)\n",
      "F1 Score: tensor(0.8089)\n",
      "Train Loss: 0.009900365303070225\n",
      "Test Loss: 0.13403520798310636\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00641111: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9573)\n",
      "Precision: tensor(0.8369)\n",
      "Recall: tensor(0.7717)\n",
      "F1 Score: tensor(0.8029)\n",
      "Train Loss: 0.015118572323926386\n",
      "Test Loss: 0.17347728088498116\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00542939: 100%|██████████| 1/1 [00:24<00:00, 24.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9629)\n",
      "Precision: tensor(0.7582)\n",
      "Recall: tensor(0.8681)\n",
      "F1 Score: tensor(0.8094)\n",
      "Train Loss: 0.011939405451157743\n",
      "Test Loss: 0.18248518677428366\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00482321: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9625)\n",
      "Precision: tensor(0.7620)\n",
      "Recall: tensor(0.8612)\n",
      "F1 Score: tensor(0.8086)\n",
      "Train Loss: 0.008417619994421638\n",
      "Test Loss: 0.1900272303260863\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00487375: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9605)\n",
      "Precision: tensor(0.7582)\n",
      "Recall: tensor(0.8458)\n",
      "F1 Score: tensor(0.7996)\n",
      "Train Loss: 0.009301807985598237\n",
      "Test Loss: 0.20584741397760808\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00463074: 100%|██████████| 1/1 [00:24<00:00, 24.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9553)\n",
      "Precision: tensor(0.7313)\n",
      "Recall: tensor(0.8194)\n",
      "F1 Score: tensor(0.7728)\n",
      "Train Loss: 0.009620091519468644\n",
      "Test Loss: 0.22291881646960973\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00322095: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9581)\n",
      "Precision: tensor(0.7524)\n",
      "Recall: tensor(0.8288)\n",
      "F1 Score: tensor(0.7887)\n",
      "Train Loss: 0.008166972436074045\n",
      "Test Loss: 0.24024268835783005\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00343340: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9579)\n",
      "Precision: tensor(0.8484)\n",
      "Recall: tensor(0.7700)\n",
      "F1 Score: tensor(0.8073)\n",
      "Train Loss: 0.009946441603958182\n",
      "Test Loss: 0.20149486605077982\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Epoch:\", epoch)\n",
    "    model.train()\n",
    "    iter_losses, epoch_losses = train_fn(model, loss_fn, x_b, y_b, lr=lr, epochs=1, batch_size=64)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        local_losses = []\n",
    "        for i in range(0, len(x_b), 64):\n",
    "            y_pred = model(x_b[i:i+64])\n",
    "            loss = loss_fn(y_pred, y_b[i:i+64].long())\n",
    "            local_losses.append(loss.item())\n",
    "\n",
    "        train_losses.append(sum(local_losses)/len(local_losses))\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        local_losses = []\n",
    "        local_y_pres = []\n",
    "        for i in range(0, len(x_d), 128):\n",
    "            y_pred = model(x_d[i:i+128]).cpu()\n",
    "            loss = loss_fn(y_pred, y_d[i:i+128].long())\n",
    "            local_losses.append(loss.item())\n",
    "            local_y_pres.append(y_pred.argmax(dim=1))\n",
    "            \n",
    "        test_loss = sum(local_losses)/len(local_losses)\n",
    "        test_losses.append(test_loss)\n",
    "        y_pred = torch.cat(local_y_pres, dim=0)\n",
    "        print(\"Accuracy:\", accuracy_score(y_d, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_d, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_d, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_d, y_pred))\n",
    "        print(\"Train Loss:\", train_losses[-1])\n",
    "        print(\"Test Loss:\", test_losses[-1])\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeel_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
