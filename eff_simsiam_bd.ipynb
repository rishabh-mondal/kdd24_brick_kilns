{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from astra.torch.utils import train_fn\n",
    "from astra.torch.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19124, 3, 224, 224]) torch.Size([19124]) torch.Size([6375, 3, 224, 224]) torch.Size([6375])\n",
      "torch.Size([25499, 3, 224, 224]) torch.Size([25499])\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/vannsh.jani/brick_kilns/ssl_exp/data\"\n",
    "x_train = torch.load(join(path, \"ban_x_train.pt\"))\n",
    "y_train = torch.load(join(path, \"ban_y_train.pt\"))\n",
    "x_test = torch.load(join(path, \"ban_x_test.pt\"))\n",
    "y_test = torch.load(join(path, \"ban_y_test.pt\"))\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "x_b = torch.cat([x_train, x_test], dim=0).to(device)\n",
    "y_b = torch.cat([y_train, y_test], dim=0).to(device)\n",
    "\n",
    "print(x_b.shape, y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5013, 3, 224, 224]) torch.Size([5013])\n"
     ]
    }
   ],
   "source": [
    "x_d = torch.load(join(path, \"delhi_test_images_50.pt\")).to(device)\n",
    "y_d = torch.load(join(path, \"delhi_test_labels_50.pt\"))\n",
    "print(x_d.shape, y_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([501, 3, 224, 224]) torch.Size([501])\n"
     ]
    }
   ],
   "source": [
    "x_d_train = torch.load(join(path, \"delhi_5_images.pt\")).to(device)\n",
    "y_d_train = torch.load(join(path, \"delhi_5_labels.pt\")).long().to(device)\n",
    "print(x_d_train.shape, y_d_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26000, 3, 224, 224]) torch.Size([26000])\n"
     ]
    }
   ],
   "source": [
    "x_b = torch.cat([x_b, x_d_train], dim=0)\n",
    "y_b = torch.cat([y_b, y_d_train], dim=0)\n",
    "print(x_b.shape, y_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downstream model\n",
    "class DownstreamModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        eff = torchvision.models.efficientnet_b0(weights=None)\n",
    "        self.eff = nn.Sequential(*list(eff.children())[:-1])\n",
    "        self.last_layer = list(eff.children())[-1]\n",
    "        self.eff.load_state_dict(torch.load(\"/home/vannsh.jani/brick_kilns/ssl_exp/simsiam/eff_simsiam_bd_150.pth\")) # load different weights\n",
    "        self.last_layer[1] = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.eff(x).squeeze(-2, -1)\n",
    "        # print(x.shape)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DownstreamModel(2).to(device)\n",
    "model(torch.rand(2, 3, 224, 224).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.11124399: 100%|██████████| 1/1 [00:24<00:00, 24.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9615)\n",
      "Precision: tensor(0.8580)\n",
      "Recall: tensor(0.7898)\n",
      "F1 Score: tensor(0.8224)\n",
      "Train Loss: 0.0343020442370966\n",
      "Test Loss: 0.10226345146074892\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.03308714: 100%|██████████| 1/1 [00:24<00:00, 24.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9649)\n",
      "Precision: tensor(0.8810)\n",
      "Recall: tensor(0.8010)\n",
      "F1 Score: tensor(0.8391)\n",
      "Train Loss: 0.020850242399587698\n",
      "Test Loss: 0.09654580564238131\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.01633801: 100%|██████████| 1/1 [00:24<00:00, 24.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9545)\n",
      "Precision: tensor(0.8887)\n",
      "Recall: tensor(0.7314)\n",
      "F1 Score: tensor(0.8024)\n",
      "Train Loss: 0.014514762636775229\n",
      "Test Loss: 0.1462044850923121\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00809162: 100%|██████████| 1/1 [00:24<00:00, 24.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9603)\n",
      "Precision: tensor(0.8580)\n",
      "Recall: tensor(0.7815)\n",
      "F1 Score: tensor(0.8179)\n",
      "Train Loss: 0.009586773465598615\n",
      "Test Loss: 0.165157688036561\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00616755: 100%|██████████| 1/1 [00:24<00:00, 24.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9543)\n",
      "Precision: tensor(0.8023)\n",
      "Recall: tensor(0.7684)\n",
      "F1 Score: tensor(0.7850)\n",
      "Train Loss: 0.008388327206130025\n",
      "Test Loss: 0.20930018946528434\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00541846: 100%|██████████| 1/1 [00:24<00:00, 24.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9671)\n",
      "Precision: tensor(0.7908)\n",
      "Recall: tensor(0.8803)\n",
      "F1 Score: tensor(0.8332)\n",
      "Train Loss: 0.006362041721801869\n",
      "Test Loss: 0.1760591345373541\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00410820: 100%|██████████| 1/1 [00:24<00:00, 24.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9633)\n",
      "Precision: tensor(0.7582)\n",
      "Recall: tensor(0.8720)\n",
      "F1 Score: tensor(0.8111)\n",
      "Train Loss: 0.007504998799226181\n",
      "Test Loss: 0.23812977252528073\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00393923: 100%|██████████| 1/1 [00:24<00:00, 24.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9645)\n",
      "Precision: tensor(0.7774)\n",
      "Recall: tensor(0.8672)\n",
      "F1 Score: tensor(0.8198)\n",
      "Train Loss: 0.005257752835987931\n",
      "Test Loss: 0.2155920799821615\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00486692: 100%|██████████| 1/1 [00:24<00:00, 24.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9669)\n",
      "Precision: tensor(0.7831)\n",
      "Recall: tensor(0.8850)\n",
      "F1 Score: tensor(0.8310)\n",
      "Train Loss: 0.005473710051635\n",
      "Test Loss: 0.23637824944453315\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00351949: 100%|██████████| 1/1 [00:24<00:00, 24.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.9655)\n",
      "Precision: tensor(0.7505)\n",
      "Recall: tensor(0.9009)\n",
      "F1 Score: tensor(0.8188)\n",
      "Train Loss: 0.011749417108497522\n",
      "Test Loss: 0.27003204984939655\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Epoch:\", epoch)\n",
    "    model.train()\n",
    "    iter_losses, epoch_losses = train_fn(model, loss_fn, x_b, y_b, lr=lr, epochs=1, batch_size=64)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        local_losses = []\n",
    "        for i in range(0, len(x_b), 64):\n",
    "            y_pred = model(x_b[i:i+64])\n",
    "            loss = loss_fn(y_pred, y_b[i:i+64].long())\n",
    "            local_losses.append(loss.item())\n",
    "\n",
    "        train_losses.append(sum(local_losses)/len(local_losses))\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        local_losses = []\n",
    "        local_y_pres = []\n",
    "        for i in range(0, len(x_d), 128):\n",
    "            y_pred = model(x_d[i:i+128]).cpu()\n",
    "            loss = loss_fn(y_pred, y_d[i:i+128].long())\n",
    "            local_losses.append(loss.item())\n",
    "            local_y_pres.append(y_pred.argmax(dim=1))\n",
    "            \n",
    "        test_loss = sum(local_losses)/len(local_losses)\n",
    "        test_losses.append(test_loss)\n",
    "        y_pred = torch.cat(local_y_pres, dim=0)\n",
    "        print(\"Accuracy:\", accuracy_score(y_d, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_d, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_d, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_d, y_pred))\n",
    "        print(\"Train Loss:\", train_losses[-1])\n",
    "        print(\"Test Loss:\", test_losses[-1])\n",
    "        \n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeel_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
